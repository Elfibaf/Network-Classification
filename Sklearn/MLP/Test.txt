Authors : Mehdi Crozes and Fabien Robin
Date : June 10th 2016

# 3 couches avec 400 neurones et 3 itérations max

Total dataset : 
Number of features : 364464
Number of labels : 364464
Iteration 1, loss = 1.39499932
Iteration 2, loss = 1.30425379
Iteration 3, loss = 1.12456954

Training  time  75.809 s
Predicting time  3.091 s
Number of Classes : 152
Test Accuracy : 0.442370165503
Training Accuracy : 0.441693372551

# 3 couches avec 300 neurones et 3 itérations max

Total dataset : 
Number of features : 364464
Number of labels : 364464
Iteration 1, loss = 1.39986141
Iteration 2, loss = 1.22163593
Iteration 3, loss = 1.05750497

Training  time  58.907 s
Predicting time  2.493 s
Number of Classes : 152
Test Accuracy : 0.688836208789
Training Accuracy : 0.691547038939

# 3 couches avec 300 neurones et 5 itérations max

Total dataset : 
Number of features : 364464
Number of labels : 364464
Iteration 1, loss = 1.39986141
Iteration 2, loss = 1.22163593
Iteration 3, loss = 1.05750497
Iteration 4, loss = 1.45746169
Iteration 5, loss = 1.26572458

Training  time  120.91 s
Predicting time  2.545 s
Number of Classes : 152
Test Accuracy : 0.651839413495
Training Accuracy : 0.649827326339

# 3 couches avec 500 neurones et 5 itérations max

Total dataset : 
Number of features : 364464
Number of labels : 364464
Iteration 1, loss = 1.38466919
Iteration 2, loss = 1.22548099
Iteration 3, loss = 1.22847218
Iteration 4, loss = 0.97203261
Iteration 5, loss = 1.05986064

Training  time  190.678 s
Predicting time  3.753 s
Number of Classes : 152
Test Accuracy : 0.65975240353
Training Accuracy : 0.65743667413

# 3 couches avec 500 neurones et 4 itérations max fonction d' activation relu

Total dataset : 
Number of features : 364464
Number of labels : 364464
Iteration 1, loss = 1.38466919
Iteration 2, loss = 1.22548099
Iteration 3, loss = 1.22847218
Iteration 4, loss = 0.97203261

Training  time  246.191 s
Predicting time  4.574 s
Number of Classes : 152
Test Accuracy : 0.801011896923
Training Accuracy : 0.801838681827

# 3 couches avec 500 neurones et 7 itérations max fonction d' activation relu

Total dataset : 
Number of features : 364464
Number of labels : 364464
Iteration 1, loss = 1.43701749
Iteration 2, loss = 1.23234399
Iteration 3, loss = 1.15672108
Iteration 4, loss = 1.10709007
Iteration 5, loss = 1.04799219
Iteration 6, loss = 0.94757916
Iteration 7, loss = 0.85711783

Training  time  208.418 s
Predicting time  2.648 s
Number of Classes : 152
Test Accuracy : 0.842343825453
Training Accuracy : 0.839691528747

# 3 couches avec 500 neurones et 20 itérations max fonction d' activation relu, descente de gradient stochastique

Total dataset : 
Number of features : 364464
Number of labels : 364464
Iteration 1, loss = 1.43701749
Iteration 2, loss = 1.23234399
Iteration 3, loss = 1.15672108
Iteration 4, loss = 1.10709007
Iteration 5, loss = 1.04799219
Iteration 6, loss = 0.94757916
Iteration 7, loss = 0.85711783
Iteration 8, loss = 0.84492786
Iteration 9, loss = 0.79514513
Iteration 10, loss = 0.79117020
Iteration 11, loss = 0.76535724
Iteration 12, loss = 0.72818314
Iteration 13, loss = 0.70443494
Iteration 14, loss = 0.69641863
Iteration 15, loss = 0.68078520
Iteration 16, loss = 0.67700079
Iteration 17, loss = 0.72129058
Iteration 18, loss = 0.70924514
Iteration 19, loss = 0.67045489
Iteration 20, loss = 0.68689939

Training  time  596.219 s
Predicting time  2.605 s
Number of Classes : 152
Test Accuracy : 0.855755300935
Training Accuracy : 0.855316300101

# Algorithme d'optimisation ADAM censé être plus efficace sur de larges datasets que le sgd.
# Pour le moment sur 7 itérations, ne pouvant pas aller plus loin dans l'amélioration de la loss function, son accuracy est de 52% franchement pas mieux qu'avant

